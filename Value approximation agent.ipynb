{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "class Connect3Environment():\n",
    "    def __init__(self, n_rows, n_cols):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.current_state = self.initialize_board()\n",
    "        \n",
    "    def initialize_board(self):\n",
    "        return np.zeros((self.n_rows, self.n_cols))\n",
    "    \n",
    "    def initialize_board(self):\n",
    "        return np.zeros((self.n_rows, self.n_cols))\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_state = self.initialize_board()\n",
    "        return self.current_state\n",
    "\n",
    "    def is_terminal(self, state):\n",
    "        reshaped_state = np.array(state).reshape(self.n_rows, self.n_cols)\n",
    "        for row in range(4):\n",
    "            for col in range(5):\n",
    "                if reshaped_state[row][col] == 0:\n",
    "                    continue\n",
    "                player = reshaped_state[row][col]\n",
    "                if (col <= 2 and all(reshaped_state[row][col+i] == player for i in range(3))) or \\\n",
    "                   (row <= 1 and all(reshaped_state[row+i][col] == player for i in range(3))) or \\\n",
    "                   (row <= 1 and col <= 2 and all(reshaped_state[row+i][col+i] == player for i in range(3))) or \\\n",
    "                   (row >= 2 and col <= 2 and all(reshaped_state[row-i][col+i] == player for i in range(3))):\n",
    "                    return True\n",
    "        # checking for draw also\n",
    "        return not any(0 in row for row in reshaped_state)\n",
    "    \n",
    "    def get_possible_actions(self, state):\n",
    "        reshaped_state = np.array(state).reshape(self.n_rows, self.n_cols)\n",
    "        return [col for col in range(5) if reshaped_state[0, col] == 0]\n",
    "    \n",
    "    def step(self, action):\n",
    "        #prev_step = deepcopy(self.current_state)\n",
    "        reshaped_board = np.array(self.current_state).reshape(self.n_rows, self.n_cols)\n",
    "        # ruch agenta\n",
    "        for row in range(3, -1, -1):\n",
    "            if reshaped_board[row, action]== 0:\n",
    "                reshaped_board[row, action] = 1\n",
    "                break\n",
    "        if self.is_terminal(reshaped_board):\n",
    "            return reshaped_board, 1, True\n",
    "        \n",
    "        # ruch przeciwnika\n",
    "        opponents_action = np.random.choice(self.get_possible_actions(reshaped_board))\n",
    "        for row in range(3, -1, -1):\n",
    "            if reshaped_board[row, opponents_action]== 0:\n",
    "                reshaped_board[row, opponents_action] = -1\n",
    "                break\n",
    "        if self.is_terminal(reshaped_board):\n",
    "            return reshaped_board, -1, True\n",
    "        self.current_state = reshaped_board\n",
    "        \n",
    "        return self.current_state, 0, self.is_terminal(self.current_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class FunctionApproximationAgent:\n",
    "    def __init__(self, alpha, gamma, epsilon, get_legal_actions):\n",
    "        self.cache = {}\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.theta_action0 = np.zeros((41, 1))\n",
    "        self.theta_action1 = np.zeros((41, 1))\n",
    "        self.theta_action2 = np.zeros((41, 1))\n",
    "        self.theta_action3 = np.zeros((41, 1))\n",
    "        self.theta_action4 = np.zeros((41, 1))\n",
    "        \n",
    "        self.theta_dict = {0: np.array([[ 0.00000000e+00],\n",
    "                        [-3.95269174e-02],\n",
    "                        [-3.45740362e-01],\n",
    "                        [-5.77726982e-02],\n",
    "                        [-2.74688350e-02],\n",
    "                        [ 1.24363031e-02],\n",
    "                        [ 2.62351874e-02],\n",
    "                        [-1.73750168e-03],\n",
    "                        [-6.84586759e-02],\n",
    "                        [-3.99119556e-02],\n",
    "                        [-6.71827303e-02],\n",
    "                        [-9.92370755e-02],\n",
    "                        [ 2.32820568e-02],\n",
    "                        [-1.25252460e-01],\n",
    "                        [-4.04794802e-01],\n",
    "                        [-4.90317472e-01],\n",
    "                        [ 3.05447132e-01],\n",
    "                        [ 1.05965089e+00],\n",
    "                        [ 5.26691409e-01],\n",
    "                        [-1.77935730e-01],\n",
    "                        [ 0.00000000e+00],\n",
    "                        [ 2.67123754e-02],\n",
    "                        [ 2.58970062e-01],\n",
    "                        [-7.45922525e-03],\n",
    "                        [-1.50867587e-02],\n",
    "                        [-2.19267512e-01],\n",
    "                        [ 1.51322412e-02],\n",
    "                        [-3.14950872e-01],\n",
    "                        [-1.16391331e-02],\n",
    "                        [-4.53650483e-02],\n",
    "                        [ 6.39783990e-01],\n",
    "                        [ 4.32725371e-01],\n",
    "                        [ 1.46990660e-01],\n",
    "                        [ 1.93574398e-01],\n",
    "                        [ 3.44024981e-01],\n",
    "                        [ 1.79210975e-01],\n",
    "                        [-1.90117141e-01],\n",
    "                        [-1.43894590e+00],\n",
    "                        [-3.28100543e-01],\n",
    "                        [ 3.42212846e-01],\n",
    "                        [ 4.41480256e+00]]),\n",
    "                1: np.array([[-1.45237206e-02],\n",
    "                        [ 0.00000000e+00],\n",
    "                        [-3.73705884e-01],\n",
    "                        [-4.22832247e-02],\n",
    "                        [-5.17735513e-02],\n",
    "                        [ 5.29805635e-02],\n",
    "                        [-6.41267765e-02],\n",
    "                        [ 4.60926486e-03],\n",
    "                        [-3.07326500e-02],\n",
    "                        [-4.34477647e-02],\n",
    "                        [-4.72613015e-01],\n",
    "                        [ 5.31762889e-02],\n",
    "                        [ 2.05336233e-01],\n",
    "                        [-3.35906872e-04],\n",
    "                        [-4.52579717e-01],\n",
    "                        [ 2.00437281e-02],\n",
    "                        [-3.36099381e-01],\n",
    "                        [ 1.12491925e+00],\n",
    "                        [ 6.47338979e-01],\n",
    "                        [-2.07113189e-01],\n",
    "                        [ 7.39635409e-02],\n",
    "                        [ 0.00000000e+00],\n",
    "                        [ 4.56718883e-01],\n",
    "                        [ 7.50255880e-02],\n",
    "                        [ 2.29564040e-02],\n",
    "                        [ 6.91039058e-02],\n",
    "                        [-2.11410320e-01],\n",
    "                        [-2.01370987e-01],\n",
    "                        [ 1.33807951e-01],\n",
    "                        [ 7.49297455e-02],\n",
    "                        [ 5.23371784e-01],\n",
    "                        [ 6.01722122e-01],\n",
    "                        [ 2.33791635e-01],\n",
    "                        [ 2.49398212e-01],\n",
    "                        [ 5.86961214e-01],\n",
    "                        [ 6.26027808e-01],\n",
    "                        [-9.71373600e-01],\n",
    "                        [-1.79712032e+00],\n",
    "                        [-8.70562998e-01],\n",
    "                        [ 3.43128954e-01],\n",
    "                        [ 4.93625072e+00]]),\n",
    "                2: np.array([[-6.24784059e-02],\n",
    "                        [-2.41954953e-03],\n",
    "                        [ 0.00000000e+00],\n",
    "                        [-5.59783097e-02],\n",
    "                        [-2.78115604e-02],\n",
    "                        [-8.17173446e-02],\n",
    "                        [ 3.85448141e-01],\n",
    "                        [-4.40272999e-01],\n",
    "                        [ 1.38824756e-01],\n",
    "                        [-5.01629251e-02],\n",
    "                        [-5.22411008e-01],\n",
    "                        [-2.91567639e-01],\n",
    "                        [ 4.19982587e-01],\n",
    "                        [-1.52794286e-02],\n",
    "                        [-4.73698551e-01],\n",
    "                        [-2.58930121e-01],\n",
    "                        [ 1.27921846e-01],\n",
    "                        [ 2.58601224e-02],\n",
    "                        [ 4.91160394e-01],\n",
    "                        [-1.26080678e-02],\n",
    "                        [ 4.45503731e-02],\n",
    "                        [ 1.71379997e-01],\n",
    "                        [ 0.00000000e+00],\n",
    "                        [ 1.12812431e-01],\n",
    "                        [ 6.30188190e-02],\n",
    "                        [ 6.21825153e-02],\n",
    "                        [ 2.21096288e-01],\n",
    "                        [-1.30977007e+00],\n",
    "                        [ 9.12354589e-02],\n",
    "                        [ 1.24932903e-01],\n",
    "                        [ 4.73632284e-01],\n",
    "                        [ 4.77188227e-01],\n",
    "                        [ 1.03767893e-01],\n",
    "                        [ 2.13435029e-01],\n",
    "                        [ 5.71781044e-01],\n",
    "                        [ 6.02978444e-01],\n",
    "                        [-4.15733215e-02],\n",
    "                        [-2.48217184e+00],\n",
    "                        [-5.79472675e-01],\n",
    "                        [ 3.72858139e-01],\n",
    "                        [ 5.62368936e+00]]),\n",
    "                3: np.array([[-6.49564875e-02],\n",
    "                        [-1.08356532e-03],\n",
    "                        [-4.46317331e-01],\n",
    "                        [ 0.00000000e+00],\n",
    "                        [-3.14198192e-02],\n",
    "                        [-8.85423195e-02],\n",
    "                        [ 2.33295460e-03],\n",
    "                        [ 8.09987737e-02],\n",
    "                        [-1.64309945e-01],\n",
    "                        [ 2.61255442e-01],\n",
    "                        [-5.31287730e-01],\n",
    "                        [-2.76053897e-01],\n",
    "                        [ 1.22154534e-01],\n",
    "                        [ 2.10557590e-01],\n",
    "                        [-4.06652169e-01],\n",
    "                        [-4.49240787e-01],\n",
    "                        [ 3.27959882e-01],\n",
    "                        [ 1.02558312e+00],\n",
    "                        [-8.84815715e-02],\n",
    "                        [ 2.27451772e-01],\n",
    "                        [ 3.23902739e-02],\n",
    "                        [ 8.20308438e-02],\n",
    "                        [ 4.92691444e-01],\n",
    "                        [ 0.00000000e+00],\n",
    "                        [ 1.42377128e-01],\n",
    "                        [ 3.45655960e-02],\n",
    "                        [ 2.60984982e-01],\n",
    "                        [-2.62493349e-01],\n",
    "                        [-5.73541736e-01],\n",
    "                        [ 1.24845111e-01],\n",
    "                        [ 4.59433098e-01],\n",
    "                        [ 4.40663516e-01],\n",
    "                        [ 1.79079384e-01],\n",
    "                        [ 9.50808676e-02],\n",
    "                        [ 6.23552361e-01],\n",
    "                        [ 6.14419800e-01],\n",
    "                        [-4.11595842e-02],\n",
    "                        [-1.74537529e+00],\n",
    "                        [-1.56885636e+00],\n",
    "                        [ 3.19260357e-01],\n",
    "                        [ 5.21878661e+00]]),\n",
    "                4: np.array([[-3.86883965e-02],\n",
    "                        [-3.57641926e-02],\n",
    "                        [-2.86149981e-01],\n",
    "                        [-9.70152443e-02],\n",
    "                        [ 0.00000000e+00],\n",
    "                        [-4.92355476e-02],\n",
    "                        [-5.34165746e-02],\n",
    "                        [ 4.07473162e-04],\n",
    "                        [-6.57024421e-03],\n",
    "                        [ 6.77447819e-02],\n",
    "                        [-4.28785500e-01],\n",
    "                        [-2.82313297e-01],\n",
    "                        [ 5.47994685e-02],\n",
    "                        [ 1.12429513e-01],\n",
    "                        [-1.25538173e-01],\n",
    "                        [-3.91086255e-01],\n",
    "                        [ 1.51564442e-03],\n",
    "                        [ 1.07780825e+00],\n",
    "                        [ 7.48641140e-01],\n",
    "                        [-3.85928221e-01],\n",
    "                        [-9.56058783e-03],\n",
    "                        [ 7.99245201e-04],\n",
    "                        [ 3.26237685e-01],\n",
    "                        [ 5.64584203e-02],\n",
    "                        [ 0.00000000e+00],\n",
    "                        [-3.24312198e-02],\n",
    "                        [ 8.63501144e-02],\n",
    "                        [-2.89008887e-01],\n",
    "                        [ 4.54905005e-02],\n",
    "                        [-1.36198861e-01],\n",
    "                        [ 4.34517278e-01],\n",
    "                        [ 4.35181026e-01],\n",
    "                        [ 2.01813672e-01],\n",
    "                        [ 1.68150994e-01],\n",
    "                        [ 7.06857870e-01],\n",
    "                        [ 6.18631902e-01],\n",
    "                        [ 9.79101052e-02],\n",
    "                        [-1.66538843e+00],\n",
    "                        [-7.49131573e-01],\n",
    "                        [-4.13824605e-01],\n",
    "                        [ 4.71202250e+00]])}\n",
    "        \n",
    "        self.get_legal_actions = get_legal_actions\n",
    "    \n",
    "    def generate_feature_vector(self, board):\n",
    "        arr1 = board==1\n",
    "        arr2 = board==-1\n",
    "        return [*arr1.flatten()]+[*arr2.flatten()]+[1] \n",
    "\n",
    "    def calculate_value(self, state, action):\n",
    "        feature_vector = self.generate_feature_vector(state)\n",
    "        value = feature_vector@self.theta_dict[action]\n",
    "        return value\n",
    "    \n",
    "    def get_value(self, state):\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "        \n",
    "        if len(possible_actions) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        max_value = float('-inf')\n",
    "        for action in possible_actions:\n",
    "            feature_vector_action = self.calculate_value(state, action)\n",
    "            if max_value < feature_vector_action:\n",
    "                max_value = feature_vector_action\n",
    "        return max_value\n",
    "    \n",
    "    def update(self, state, action, reward, next_state):\n",
    "        valid_actions_next_state = self.get_legal_actions(next_state)\n",
    "        if len(valid_actions_next_state) > 0:\n",
    "            value_next_state = self.get_value(next_state)\n",
    "        else:\n",
    "            value_next_state = 0\n",
    "        error = reward+self.gamma*value_next_state-self.calculate_value(state,action)\n",
    "        delta_theta = self.alpha*error*self.generate_feature_vector(state)\n",
    "        self.theta_dict[action] = self.theta_dict[action]+delta_theta.reshape(self.theta_action1.shape)\n",
    "        \n",
    "    def get_best_action(self, state):\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "        \n",
    "        if len(possible_actions) == 0:\n",
    "            return None\n",
    "        \n",
    "        best_actions = []\n",
    "        action_value = float('-inf')\n",
    "        for action in possible_actions:\n",
    "            value = self.calculate_value(state, action)\n",
    "            if action_value < value:\n",
    "                best_actions = [action]\n",
    "                action_value = value\n",
    "            elif action_value == value:\n",
    "                best_actions.append(action)\n",
    "        best_action = np.random.choice(best_actions)\n",
    "        return best_action\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        # Pick Action\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        # If there are no legal actions, return None\n",
    "        if len(possible_actions) == 0:\n",
    "            return None\n",
    "\n",
    "        random_number = random.random()\n",
    "        if random_number <= self.epsilon:\n",
    "            exploration = True\n",
    "        else:\n",
    "            exploration = False\n",
    "        \n",
    "        if exploration == False:\n",
    "            chosen_action = self.get_best_action(state)\n",
    "        else:\n",
    "            if len(possible_actions)>1:\n",
    "                # possible_actions.remove(self.get_best_action(state))\n",
    "                chosen_action = random.choice(possible_actions)\n",
    "            else: \n",
    "                chosen_action = possible_actions[0]\n",
    "        \n",
    "        return chosen_action\n",
    "        \n",
    "    def turn_off_learning(self):\n",
    "        \"\"\"\n",
    "        Function turns off agent learning.\n",
    "        \"\"\"\n",
    "        self.epsilon = 0\n",
    "        self.alpha = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_and_train(env, agent):\n",
    "    \"\"\"\n",
    "    This function should\n",
    "    - run a full game, actions given by agent's e-greedy policy\n",
    "    - train agent using agent.update(...) whenever it is possible\n",
    "    - return total reward\n",
    "    \"\"\"\n",
    "    total_reward = 0.0\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        # get agent to pick action given state state.\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        #\n",
    "        # INSERT CODE HERE to train (update) agent for state\n",
    "        #        \n",
    "        agent.update(state, action, reward, next_state)\n",
    "\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Connect3Environment(4, 5)\n",
    "agent = FunctionApproximationAgent(0.0001, 0.9, 0.15, environment.get_possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500000):\n",
    "    play_and_train(environment, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.turn_off_learning()\n",
    "play_and_train(environment, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def game_is_terminal(state):\n",
    "    reshaped_state = np.array(state).reshape(4,5)\n",
    "    #print(reshaped_state)\n",
    "    for row in range(4):\n",
    "        for col in range(5):\n",
    "            if reshaped_state[row][col] == 0:\n",
    "                continue\n",
    "            player = reshaped_state[row][col]\n",
    "            if (col <= 2 and all(reshaped_state[row][col+i] == player for i in range(3))) or \\\n",
    "               (row <= 1 and all(reshaped_state[row+i][col] == player for i in range(3))) or \\\n",
    "               (row <= 1 and col <= 2 and all(reshaped_state[row+i][col+i] == player for i in range(3))) or \\\n",
    "               (row >= 2 and col <= 2 and all(reshaped_state[row-i][col+i] == player for i in range(3))):\n",
    "                return True\n",
    "    # checking for draw also\n",
    "    return not any(0 in row for row in reshaped_state)\n",
    "\n",
    "def game_step(board, action, player):\n",
    "    next_state = deepcopy(board)\n",
    "    for row in range(3, -1, -1):\n",
    "        if next_state[row, action] == 0:\n",
    "            next_state[row, action] = player\n",
    "            break\n",
    "    \n",
    "    return next_state, game_is_terminal(next_state)\n",
    "\n",
    "def game(env, agent):\n",
    "    clear = lambda: os.system('cls')\n",
    "    \n",
    "    player_round = 1\n",
    "    board = env.reset()\n",
    "    print(board)\n",
    "    \n",
    "    while True:\n",
    "        if player_round == 1:\n",
    "            agent_move = agent.get_action(board)\n",
    "            board, done = game_step(board, agent_move, player_round)\n",
    "            player_round = 0 - player_round\n",
    "        else:\n",
    "            player_move = int(input('Podaj swój ruch (0-4): '))\n",
    "            board, done = game_step(board, player_move, player_round)\n",
    "            player_round = 0 - player_round\n",
    "        #clear()\n",
    "        print(board)\n",
    "        \n",
    "        if env.is_terminal(board):\n",
    "            print(f'Wygrał gracz {0 - player_round}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0. -1.]]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1. -1.]]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1. -1.]]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0. -1.  1.  1. -1.]]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0. -1.  1.  1. -1.]]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.]\n",
      " [ 0. -1.  1.  1. -1.]]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  1.  1. -1.]\n",
      " [ 0. -1.  1.  1. -1.]]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.]\n",
      " [ 0.  0.  1.  1. -1.]\n",
      " [ 0. -1.  1.  1. -1.]]\n",
      "Wygrał gracz 1\n"
     ]
    }
   ],
   "source": [
    "agent.turn_off_learning()\n",
    "game(environment, agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
